{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca6b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import csv\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/hb_train_1.csv\", header=None)\n",
    "val = pd.read_csv(\"data/hb_val.csv\", header=None)\n",
    "test = pd.read_csv(\"data/hb_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371d55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = train.iloc[:,0]\n",
    "# X_train = train.iloc[:, [1,27]]\n",
    "# y_test = test.iloc[:,0]\n",
    "# X_test = test.iloc[:, [1,27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c19f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "# param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "# model = xgb.train(param, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd8ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf33900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, xgb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee61220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the true positive, false positive, true negative, and false negative counts.\n",
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "# perf_measure(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04eba0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "train = loadtxt(\"data/hb_train_1.csv\", delimiter=\",\" )\n",
    "val = loadtxt(\"data/hb_val.csv\", delimiter=\",\" )\n",
    "test = loadtxt(\"data/hb_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b98bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[:, 0]\n",
    "X_train = train[:, 1:27]\n",
    "y_test = test[:, 0]\n",
    "X_test = test[:, 1:27]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65748909",
   "metadata": {},
   "source": [
    "## XGBoost on one site's data (61% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85797cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.96      0.71     20032\n",
      "         1.0       0.87      0.25      0.39     19968\n",
      "\n",
      "    accuracy                           0.61     40000\n",
      "   macro avg       0.71      0.61      0.55     40000\n",
      "weighted avg       0.71      0.61      0.55     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(use_label_encoder=False)\n",
    "model.fit(X_train, y_train, verbose=2)\n",
    "# make predictions for test data\n",
    "xgb_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b877ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5006, 775, 19257, 14962)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_measure(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81173f70",
   "metadata": {},
   "source": [
    "# 2 sites data regular xgboost (71% accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad3ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:49] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.71      0.71     20032\n",
      "         1.0       0.71      0.71      0.71     19968\n",
      "\n",
      "    accuracy                           0.71     40000\n",
      "   macro avg       0.71      0.71      0.71     40000\n",
      "weighted avg       0.71      0.71      0.71     40000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5006, 775, 19257, 14962)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input2 = loadtxt(\"data/hb_train_2.csv\", delimiter=\",\" )\n",
    "\n",
    "train2 = np.concatenate([train, input2])\n",
    "\n",
    "yt2 = train2[:, 0]\n",
    "xt2 = train2[:, 1:27]\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False)\n",
    "model.fit(xt2, yt2)\n",
    "# make predictions for test data\n",
    "xgb_pred2 = model.predict(X_test)\n",
    "print(classification_report(y_test, xgb_pred2))\n",
    "perf_measure(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20046c95",
   "metadata": {},
   "source": [
    "# Federated: Voting between two sites (70% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a942e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.96      0.71     20032\n",
      "         1.0       0.87      0.25      0.39     19968\n",
      "\n",
      "    accuracy                           0.61     40000\n",
      "   macro avg       0.71      0.61      0.55     40000\n",
      "weighted avg       0.71      0.61      0.55     40000\n",
      "\n",
      "(5006, 775, 19257, 14962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:08] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.25      0.38     20032\n",
      "         1.0       0.56      0.96      0.71     19968\n",
      "\n",
      "    accuracy                           0.60     40000\n",
      "   macro avg       0.72      0.60      0.55     40000\n",
      "weighted avg       0.72      0.60      0.55     40000\n",
      "\n",
      "(19244, 15106, 4926, 724)\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBClassifier(use_label_encoder=False)\n",
    "model1.fit(X_train, y_train)\n",
    "pred1 = model1.predict(X_test)\n",
    "print(classification_report(y_test, pred1))\n",
    "print(perf_measure(y_test, pred1))\n",
    "\n",
    "data2 = loadtxt(\"data/hb_train_2.csv\", delimiter=\",\" )\n",
    "xt2 = data2[:, 1:27]\n",
    "yt2 = data2[:, 0]\n",
    "model2 = XGBClassifier(use_label_encoder=False)\n",
    "model2.fit(xt2, yt2)\n",
    "pred2 = model2.predict(X_test)\n",
    "print(classification_report(y_test, pred2))\n",
    "print(perf_measure(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6060f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9758602 , 0.02413985],\n",
       "       [0.8741944 , 0.1258056 ],\n",
       "       [0.96343887, 0.0365611 ],\n",
       "       ...,\n",
       "       [0.20763099, 0.792369  ],\n",
       "       [0.69789803, 0.302102  ],\n",
       "       [0.62504923, 0.3749508 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1 = model1.predict_proba(X_test)\n",
    "prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ec2b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9060826 , 0.09391744],\n",
       "       [0.3606001 , 0.6393999 ],\n",
       "       [0.591596  , 0.408404  ],\n",
       "       ...,\n",
       "       [0.05627292, 0.9437271 ],\n",
       "       [0.06083065, 0.93916935],\n",
       "       [0.1133765 , 0.8866235 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob2 = model2.predict_proba(X_test)\n",
    "prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb3442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.71      0.70     20032\n",
      "         1.0       0.70      0.70      0.70     19968\n",
      "\n",
      "    accuracy                           0.70     40000\n",
      "   macro avg       0.70      0.70      0.70     40000\n",
      "weighted avg       0.70      0.70      0.70     40000\n",
      "\n",
      "TP, FP, TN, FN: \n",
      "(13934, 5898, 14134, 6034)\n"
     ]
    }
   ],
   "source": [
    "average = prob1 / 2 + prob2 / 2\n",
    "avg_pred = []\n",
    "for ar in average:\n",
    "    if ar[0] > ar[1]:\n",
    "        avg_pred.append(0)\n",
    "    else:\n",
    "        avg_pred.append(1)\n",
    "print(classification_report(y_test, avg_pred))\n",
    "print(\"TP, FP, TN, FN: \")\n",
    "print(perf_measure(y_test, avg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356dec88",
   "metadata": {},
   "source": [
    "# Federated Voting between 2 sites (logistic reg voting) The log reg part trained with central site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a4a5b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9060826 , 0.09391744],\n",
       "       [0.3606001 , 0.6393999 ],\n",
       "       [0.591596  , 0.408404  ],\n",
       "       ...,\n",
       "       [0.05627292, 0.9437271 ],\n",
       "       [0.06083065, 0.93916935],\n",
       "       [0.1133765 , 0.8866235 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d0adfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9758602 , 0.02413985],\n",
       "       [0.8741944 , 0.1258056 ],\n",
       "       [0.96343887, 0.0365611 ],\n",
       "       ...,\n",
       "       [0.20763099, 0.792369  ],\n",
       "       [0.69789803, 0.302102  ],\n",
       "       [0.62504923, 0.3749508 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105b6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_test = []\n",
    "for i in range(len(prob1)):\n",
    "    prob_test.append([prob1[i][1], prob2[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "442c62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict_proba(X_train)\n",
    "pred2 = model2.predict_proba(X_train)\n",
    "probs = []\n",
    "for i in range(len(pred1)):\n",
    "    probs.append([pred1[i][1], pred2[i][1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5e1e6",
   "metadata": {},
   "source": [
    "## When testing it on the central site, the results are very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41bcc13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.96      0.92     64040\n",
      "         1.0       0.76      0.54      0.63     15960\n",
      "\n",
      "    accuracy                           0.87     80000\n",
      "   macro avg       0.83      0.75      0.78     80000\n",
      "weighted avg       0.87      0.87      0.87     80000\n",
      "\n",
      "TP, FP, TN, FN: \n",
      "(8621, 2762, 61278, 7339)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0).fit(probs, y_train)\n",
    "lr_pred = lr.predict(probs)\n",
    "print(classification_report(y_train, lr_pred))\n",
    "print(\"TP, FP, TN, FN: \")\n",
    "print(perf_measure(y_train, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60e829",
   "metadata": {},
   "source": [
    "# But when it is tested on test set, we see that it is overfitting and actually hurting overall effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48037056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.93      0.72     20032\n",
      "         1.0       0.83      0.35      0.49     19968\n",
      "\n",
      "    accuracy                           0.64     40000\n",
      "   macro avg       0.71      0.64      0.60     40000\n",
      "weighted avg       0.71      0.64      0.60     40000\n",
      "\n",
      "TP, FP, TN, FN: \n",
      "(6947, 1450, 18582, 13021)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0).fit(probs, y_train)\n",
    "lr_pred = lr.predict(prob_test)\n",
    "print(classification_report(y_test, lr_pred))\n",
    "print(\"TP, FP, TN, FN: \")\n",
    "print(perf_measure(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d758b",
   "metadata": {},
   "source": [
    "# Saving model and then passing around sites, not parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b6aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_model('model1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "750586bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:16] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.26      0.40     20032\n",
      "         1.0       0.56      0.95      0.71     19968\n",
      "\n",
      "    accuracy                           0.61     40000\n",
      "   macro avg       0.70      0.61      0.55     40000\n",
      "weighted avg       0.70      0.61      0.55     40000\n",
      "\n",
      "TP, FP, TN, FN: \n",
      "(19013, 14780, 5252, 955)\n"
     ]
    }
   ],
   "source": [
    "incr_model = XGBClassifier(use_label_encoder=False)\n",
    "incr_model.fit(xt2, yt2, xgb_model='model1.model')\n",
    "incr_model.save_model('incr_model.model')\n",
    "incr_pred = incr_model.predict(X_test)\n",
    "print(classification_report(y_test, incr_pred))\n",
    "print(\"TP, FP, TN, FN: \")\n",
    "print(perf_measure(y_test, incr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b986e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhang/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:104: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incr_model2 = XGBClassifier(use_label_encoder=False)\n",
    "incr_model2.fit(X_train, y_train, xgb_model='incr_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb6f90e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.95      0.71     20032\n",
      "         1.0       0.84      0.27      0.41     19968\n",
      "\n",
      "    accuracy                           0.61     40000\n",
      "   macro avg       0.71      0.61      0.56     40000\n",
      "weighted avg       0.71      0.61      0.56     40000\n",
      "\n",
      "TP, FP, TN, FN: \n",
      "(5379, 988, 19044, 14589)\n"
     ]
    }
   ],
   "source": [
    "incr_pred2 = incr_model2.predict(X_test)\n",
    "print(classification_report(y_test, incr_pred2))\n",
    "print(\"TP, FP, TN, FN: \")\n",
    "print(perf_measure(y_test, incr_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6097b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
